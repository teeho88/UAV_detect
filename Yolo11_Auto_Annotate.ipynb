{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_imshow(img):\n",
    "    image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(image, rows, cols):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Calculate the height and width of each sub-image\n",
    "    sub_height = height // rows\n",
    "    sub_width = width // cols\n",
    "    \n",
    "    # Create a list to store the sub-images\n",
    "    sub_images = []\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Calculate the coordinates of each sub-image\n",
    "            start_y = row * sub_height\n",
    "            start_x = col * sub_width\n",
    "            end_y = (row + 1) * sub_height\n",
    "            end_x = (col + 1) * sub_width\n",
    "            \n",
    "            # Crop the sub-image\n",
    "            sub_image = image[start_y:end_y, start_x:end_x]\n",
    "            sub_images.append(sub_image)\n",
    "    \n",
    "    return sub_images\n",
    "\n",
    "def get_center_region(image):\n",
    "    # Detect the UAV in the frame\n",
    "    # Get image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the center and radius for the circular crop\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "    radius = min(center_x, center_y, width//4)  # Radius is limited by the smallest dimension\n",
    "\n",
    "    # Crop the rectangular bounding box around the circle\n",
    "    x1, y1 = center_x - radius, center_y - radius\n",
    "    x2, y2 = center_x + radius, center_y + radius\n",
    "\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "def extract_images(video_path, output_dir, num_frames):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the interval to extract evenly spaced frames\n",
    "    interval = total_frames / num_frames\n",
    "    \n",
    "    file_name = os.path.join(output_dir, os.path.splitext(os.path.basename(video_path))[0])\n",
    "    num_images = 0\n",
    "    for i in tqdm(range(num_frames), desc=f\"Progressive {file_name}\", leave=True):\n",
    "        # Set the position of the next frame\n",
    "        frame_id = round(i * interval)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        \n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Break if unable to read the frame\n",
    "        \n",
    "        center_region = get_center_region(frame)\n",
    "        cv2.imwrite(f\"{file_name}_{i}.jpg\", center_region)\n",
    "        num_images += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progressive Images/Data\\WIN_20241101_08_28_33_Pro:  28%|██▊       | 110/400 [00:09<00:26, 11.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m num_imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, video_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(video_names):\n\u001b[1;32m----> 7\u001b[0m     num \u001b[38;5;241m=\u001b[39m \u001b[43mextract_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Change to the video file path if needed\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     num_imgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_imgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m, in \u001b[0;36mextract_images\u001b[1;34m(video_path, output_dir, num_frames)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_frames), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgressive \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Set the position of the next frame\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     frame_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(i \u001b[38;5;241m*\u001b[39m interval)\n\u001b[1;32m---> 55\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Read the frame\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Capture video from the webcam or a video file\n",
    "video_path = \"Images/Sources\"\n",
    "output_path = \"Images/Data\"\n",
    "video_names = os.listdir(video_path)\n",
    "num_imgs = 0\n",
    "for i, video_name in enumerate(video_names):\n",
    "    num = extract_images(os.path.join(video_path, video_name), output_path, 400)  # Change to the video file path if needed\n",
    "    num_imgs += num\n",
    "print(f\"num images: {num_imgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "video_path = \"Images/Sources/WIN_20241106_15_10_23_Pro.mp4\"\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "# Get the total number of frames in the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "interval = round(total_frames / 500)\n",
    "print(interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Auto annotation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\Teeho\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11x.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "results = model.train(data=\"datasetConfigure.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Export</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11x_best.pt\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "model.export(format=\"onnx\")  # creates 'yolo11n.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the exported ONNX model\n",
    "onnx_model = YOLO(\"yolo11n.onnx\")\n",
    "\n",
    "# Run inference\n",
    "results = onnx_model(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
